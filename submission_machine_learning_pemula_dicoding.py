# -*- coding: utf-8 -*-
"""Submission Machine Learning Pemula Dicoding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nZyAEipRZAeQs7LYT2-KZgyvzlI1bOP4

Nama              : Dwi Abriansya Alimuddin

No Registrasi FGA : 0182180121-127

# Import Module yang dibutuhkan
"""

import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import zipfile,os

"""## Install dan import module `splitfolder`
Module splitfolder dapat memudahkan split data train dan test yang berbentuk images
"""

# install module splitfolder
!pip install split-folders tqdm

import splitfolders

"""# Menyiapkan Data"""

!wget --no-check-certificate \
  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip \
  -O /tmp/rockpaperscissors.zip

"""## Ekstraksi data dari file zip
File zip yang telah diakses di atas akan diekstrak agar data yang terdapat di dalamnya dapat diakses
"""

# Melakukan ekstraksi pada file zip
local_zip = '/tmp/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

# Inisiasi direktori base dan direktori data
base_dir = '/tmp/rockpaperscissors'
data_dir = os.path.join(base_dir, 'rps-cv-images')

# Melihat isi dari direktori data
os.listdir(data_dir)

"""## Train Test Split
Data yang terdapat dalam direktori data akan displit menjadi data train dan data validation dengan rasio 60:40. Hasil split akan tersimpan dalam direktori baru.
"""

# Split data menjadi data train dan data validation dengan ratio 60:40
splitfolders.ratio(data_dir, output=data_dir+'/data', ratio=(.6, .4))

# Melihat isi dari direktori baru hasil split
os.listdir(data_dir+'/data')

# Melihat jumlah data train dan data validation
print('Jumlah data train: ', len(os.listdir(data_dir+'/data/train/rock')+os.listdir(data_dir+'/data/train/paper')+os.listdir(data_dir+'/data/train/scissors')))
print('Jumlah data validation: ', len(os.listdir(data_dir+'/data/val/rock')+os.listdir(data_dir+'/data/val/paper')+os.listdir(data_dir+'/data/val/scissors')))

# Inisiasi direktori data train dan data validation
train_dir = os.path.join(data_dir, 'data/train')
val_dir = os.path.join(data_dir, 'data/val')

"""# Image Data Generator"""

# Augmentasi gambar
train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest')

test_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest')

# Mempersiapkan data train dan data validation
train_generator = train_datagen.flow_from_directory(
        train_dir,                        # Direktori data train
        target_size=(200, 300),           # Resolusi data (200x300 pixel)
        batch_size=10,
        class_mode='categorical')         # Klasifikasi 3 class, sehingga menggunakan 'categorical'

validation_generator = test_datagen.flow_from_directory(
        val_dir,                          # Direktori data validasi
        target_size=(200, 300),           # Resolusi data (200x300 pixel)
        batch_size=10,
        class_mode='categorical')         # Klasifikasi 3 class, sehingga menggunakan 'categorical'

"""# Convolution Neural Network

## Arsitektur CNN
"""

model = tf.keras.models.Sequential([
    # Convolution layer pertama
    # Resolusi data (300x200 pixel) dengan warna RGB, shingga input_shape = (200, 300, 3)
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(200, 300, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    # Convolution layer kedua
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # Convolution layer ketiga
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # Convolution layer keempat
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # Convolution layer kelima
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # Convolution layer keenam
    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # Meratakan input
    tf.keras.layers.Flatten(),
    # Hidden layer dengan 512 neuron
    tf.keras.layers.Dense(512, activation='relu'),
    # Output layer, klasifikasi 3 class sehingga menggunakan aktivasi softmax
    tf.keras.layers.Dense(3, activation='softmax')
])

"""## Compile model"""

# Compile model dengan parameter loss, optimizer, dan metrics
model.compile(
    optimizer='rmsprop',
    loss='categorical_crossentropy',
    metrics=['accuracy'])

"""# Train Model"""

# Train model yang telah dibuat dengan menggunakan data yang telah disiapkan dan epoch sebanyak 25.
history = model.fit(
      train_generator,                        # Data train yang telah disiapkan
      steps_per_epoch=20,                     # Jumlah step per epoch
      epochs=25,                              # Jumlah epoch
      validation_data=validation_generator,   # Data validation yang telah disiapkan
      validation_steps=5,                     
      verbose=2)                              # Menampilkan hasil tiap epoch

"""# Test Model"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():
 
  # predicting images
  path = fn
  img = image.load_img(path, target_size=(200, 300))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  
  print(fn)
  if classes[0][0] == 1:
    print('paper')
  elif classes[0][1] == 1:
     print('rock')
  else:
    print('scissors')